{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제1번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.datasets import load_breast_cancer, load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed =2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,415\n",
      "Trainable params: 1,415\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(30, input_dim=30, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = MODEL_DIR + \"final{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpointer_callback = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 19.62851, saving model to ./model/final001-19.6285.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 19.62851 to 17.29044, saving model to ./model/final002-17.2904.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 17.29044 to 14.97553, saving model to ./model/final003-14.9755.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 14.97553 to 12.68668, saving model to ./model/final004-12.6867.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 12.68668 to 10.44045, saving model to ./model/final005-10.4405.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 10.44045 to 8.24197, saving model to ./model/final006-8.2420.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 8.24197 to 6.15014, saving model to ./model/final007-6.1501.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 6.15014 to 4.20904, saving model to ./model/final008-4.2090.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.20904 to 2.54544, saving model to ./model/final009-2.5454.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.54544 to 1.32435, saving model to ./model/final010-1.3243.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.32435 to 0.64941, saving model to ./model/final011-0.6494.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.64941 to 0.45346, saving model to ./model/final012-0.4535.hdf5\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.45346\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.45346 to 0.38874, saving model to ./model/final024-0.3887.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.38874 to 0.32823, saving model to ./model/final025-0.3282.hdf5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.32823\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.32823 to 0.32134, saving model to ./model/final044-0.3213.hdf5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.32134 to 0.31298, saving model to ./model/final045-0.3130.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.31298 to 0.30729, saving model to ./model/final046-0.3073.hdf5\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.30729\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.30729\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.30729\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.30729\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.30729\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.30729\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.30729\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.30729\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.30729 to 0.30495, saving model to ./model/final055-0.3050.hdf5\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.30495 to 0.28128, saving model to ./model/final056-0.2813.hdf5\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.28128 to 0.26307, saving model to ./model/final057-0.2631.hdf5\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.26307 to 0.25062, saving model to ./model/final058-0.2506.hdf5\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.25062 to 0.24265, saving model to ./model/final059-0.2427.hdf5\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.24265 to 0.23718, saving model to ./model/final060-0.2372.hdf5\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.23718 to 0.23296, saving model to ./model/final061-0.2330.hdf5\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.23296 to 0.22943, saving model to ./model/final062-0.2294.hdf5\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.22943 to 0.22707, saving model to ./model/final063-0.2271.hdf5\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.22707 to 0.22699, saving model to ./model/final064-0.2270.hdf5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.22699\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.22699\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.22699\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.22699\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.22699\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.22699\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.22699\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.22699\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.22699 to 0.21956, saving model to ./model/final073-0.2196.hdf5\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.21956 to 0.21352, saving model to ./model/final074-0.2135.hdf5\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.21352 to 0.20954, saving model to ./model/final075-0.2095.hdf5\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.20954 to 0.20728, saving model to ./model/final076-0.2073.hdf5\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.20728 to 0.20625, saving model to ./model/final077-0.2063.hdf5\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.20625\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.20625\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.20625\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.20625\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.20625\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.20625\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.20625\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.20625\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.20625\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.20625\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.20625 to 0.20449, saving model to ./model/final088-0.2045.hdf5\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.20449 to 0.20244, saving model to ./model/final089-0.2024.hdf5\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.20244 to 0.20137, saving model to ./model/final090-0.2014.hdf5\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.20137 to 0.20122, saving model to ./model/final091-0.2012.hdf5\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.20122\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.20122 to 0.19988, saving model to ./model/final131-0.1999.hdf5\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.19988 to 0.19700, saving model to ./model/final132-0.1970.hdf5\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.19700 to 0.19549, saving model to ./model/final133-0.1955.hdf5\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.19549\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.19549\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.19549\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.19549\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.19549\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.19549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00140: val_loss did not improve from 0.19549\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.19549\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.19549 to 0.19530, saving model to ./model/final142-0.1953.hdf5\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.19530\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.19530\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.19530\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.19530\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.19530\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.19530 to 0.19506, saving model to ./model/final148-0.1951.hdf5\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.19506 to 0.19411, saving model to ./model/final149-0.1941.hdf5\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.19411 to 0.19399, saving model to ./model/final150-0.1940.hdf5\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.19399 to 0.19383, saving model to ./model/final151-0.1938.hdf5\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.19383 to 0.19313, saving model to ./model/final152-0.1931.hdf5\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.19313 to 0.19307, saving model to ./model/final153-0.1931.hdf5\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.19307\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.19307\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.19307\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.19307\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.19307\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.19307 to 0.19216, saving model to ./model/final159-0.1922.hdf5\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.19216 to 0.19092, saving model to ./model/final160-0.1909.hdf5\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.19092 to 0.19004, saving model to ./model/final161-0.1900.hdf5\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.19004 to 0.18994, saving model to ./model/final162-0.1899.hdf5\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.18994\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.18994\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.18994\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.18994\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.18994 to 0.18943, saving model to ./model/final167-0.1894.hdf5\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.18943 to 0.18852, saving model to ./model/final168-0.1885.hdf5\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.18852 to 0.18769, saving model to ./model/final169-0.1877.hdf5\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.18769 to 0.18708, saving model to ./model/final170-0.1871.hdf5\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.18708 to 0.18688, saving model to ./model/final171-0.1869.hdf5\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.18688\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.18688\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.18688\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.18688\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.18688 to 0.18608, saving model to ./model/final176-0.1861.hdf5\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.18608 to 0.18541, saving model to ./model/final177-0.1854.hdf5\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.18541 to 0.18479, saving model to ./model/final178-0.1848.hdf5\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.18479 to 0.18435, saving model to ./model/final179-0.1843.hdf5\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.18435\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.18435\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.18435\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.18435\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.18435 to 0.18385, saving model to ./model/final184-0.1839.hdf5\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.18385 to 0.18290, saving model to ./model/final185-0.1829.hdf5\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.18290\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.18290\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.18290\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.18290 to 0.18228, saving model to ./model/final189-0.1823.hdf5\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.18228 to 0.18184, saving model to ./model/final190-0.1818.hdf5\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.18184 to 0.18165, saving model to ./model/final191-0.1816.hdf5\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.18165 to 0.18121, saving model to ./model/final192-0.1812.hdf5\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.18121 to 0.18095, saving model to ./model/final193-0.1810.hdf5\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.18095\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.18095\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.18095\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.18095\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.18095\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.18095\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.18095 to 0.17913, saving model to ./model/final200-0.1791.hdf5\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.17913\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.17913\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.17913 to 0.17833, saving model to ./model/final203-0.1783.hdf5\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.17833 to 0.17718, saving model to ./model/final204-0.1772.hdf5\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.17718\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.17718\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.17718\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.17718\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.17718 to 0.17704, saving model to ./model/final209-0.1770.hdf5\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.17704 to 0.17636, saving model to ./model/final210-0.1764.hdf5\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.17636\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.17636\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.17636\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.17636 to 0.17540, saving model to ./model/final214-0.1754.hdf5\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.17540 to 0.17434, saving model to ./model/final215-0.1743.hdf5\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.17434\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.17434\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.17434\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.17434 to 0.17431, saving model to ./model/final219-0.1743.hdf5\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.17431 to 0.17303, saving model to ./model/final220-0.1730.hdf5\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.17303\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.17303\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.17303\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.17303\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.17303\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.17303 to 0.17256, saving model to ./model/final226-0.1726.hdf5\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.17256\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.17256\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.17256\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.17256\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.17256\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.17256\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.17256 to 0.17121, saving model to ./model/final233-0.1712.hdf5\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.17121 to 0.17093, saving model to ./model/final234-0.1709.hdf5\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.17093\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.17093\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.17093\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.17093\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.17093\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.17093\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.17093 to 0.17081, saving model to ./model/final241-0.1708.hdf5\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.17081 to 0.17021, saving model to ./model/final242-0.1702.hdf5\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.17021 to 0.16993, saving model to ./model/final243-0.1699.hdf5\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.16993\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.16993 to 0.16952, saving model to ./model/final245-0.1695.hdf5\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.16952 to 0.16860, saving model to ./model/final246-0.1686.hdf5\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.16860\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.16860\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.16860 to 0.16846, saving model to ./model/final249-0.1685.hdf5\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.16846\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.16846\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.16846\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.16846 to 0.16530, saving model to ./model/final253-0.1653.hdf5\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.16530\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.16530\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.16530\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.16530\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.16530\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.16530\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.16530\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.16530\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.16530\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.16530 to 0.16458, saving model to ./model/final263-0.1646.hdf5\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.16458\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.16458\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.16458\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.16458 to 0.16280, saving model to ./model/final267-0.1628.hdf5\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.16280\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.16280\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.16280\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.16280\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.16280\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.16280\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.16280\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00275: val_loss did not improve from 0.16280\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.16280\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.16280 to 0.16204, saving model to ./model/final277-0.1620.hdf5\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.16204 to 0.16158, saving model to ./model/final278-0.1616.hdf5\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.16158\n",
      "\n",
      "Epoch 00296: val_loss improved from 0.16158 to 0.16156, saving model to ./model/final296-0.1616.hdf5\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.16156\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.16156\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.16156\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.16156 to 0.16135, saving model to ./model/final300-0.1613.hdf5\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.16135\n",
      "\n",
      "Epoch 00317: val_loss improved from 0.16135 to 0.16034, saving model to ./model/final317-0.1603.hdf5\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.16034\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.16034 to 0.16007, saving model to ./model/final336-0.1601.hdf5\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.16007\n",
      "\n",
      "Epoch 00351: val_loss improved from 0.16007 to 0.15854, saving model to ./model/final351-0.1585.hdf5\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.15854\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.15854 to 0.15787, saving model to ./model/final363-0.1579.hdf5\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.15787\n",
      "\n",
      "Epoch 00375: val_loss improved from 0.15787 to 0.15560, saving model to ./model/final375-0.1556.hdf5\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.15560\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.15560\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.15560\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.15560\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.15560\n",
      "\n",
      "Epoch 00381: val_loss improved from 0.15560 to 0.15407, saving model to ./model/final381-0.1541.hdf5\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.15407\n",
      "\n",
      "Epoch 00406: val_loss improved from 0.15407 to 0.15406, saving model to ./model/final406-0.1541.hdf5\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.15406\n",
      "\n",
      "Epoch 00423: val_loss improved from 0.15406 to 0.15366, saving model to ./model/final423-0.1537.hdf5\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.15366\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.15366\n",
      "\n",
      "Epoch 00426: val_loss improved from 0.15366 to 0.15340, saving model to ./model/final426-0.1534.hdf5\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.15340\n",
      "\n",
      "Epoch 00428: val_loss improved from 0.15340 to 0.15318, saving model to ./model/final428-0.1532.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00429: val_loss improved from 0.15318 to 0.14960, saving model to ./model/final429-0.1496.hdf5\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.14960\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.14960\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.14960\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.14960\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.14960\n",
      "\n",
      "Epoch 00435: val_loss improved from 0.14960 to 0.14950, saving model to ./model/final435-0.1495.hdf5\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.14950\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.14950\n",
      "\n",
      "Epoch 00438: val_loss improved from 0.14950 to 0.14862, saving model to ./model/final438-0.1486.hdf5\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.14862\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.14862\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.14862\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.14862\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.14862\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.14862\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.14862\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.14862\n",
      "\n",
      "Epoch 00447: val_loss improved from 0.14862 to 0.14628, saving model to ./model/final447-0.1463.hdf5\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.14628\n",
      "\n",
      "Epoch 00459: val_loss improved from 0.14628 to 0.14600, saving model to ./model/final459-0.1460.hdf5\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.14600\n",
      "\n",
      "Epoch 00477: val_loss improved from 0.14600 to 0.14486, saving model to ./model/final477-0.1449.hdf5\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.14486\n",
      "\n",
      "Epoch 00507: val_loss improved from 0.14486 to 0.14326, saving model to ./model/final507-0.1433.hdf5\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.14326\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.14326\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.14326\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.14326\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.14326\n",
      "\n",
      "Epoch 00513: val_loss improved from 0.14326 to 0.14095, saving model to ./model/final513-0.1410.hdf5\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.14095\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.14095\n",
      "\n",
      "Epoch 00516: val_loss improved from 0.14095 to 0.13953, saving model to ./model/final516-0.1395.hdf5\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.13953\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.13953\n",
      "\n",
      "Epoch 00519: val_loss improved from 0.13953 to 0.13757, saving model to ./model/final519-0.1376.hdf5\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.13757\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.13757\n",
      "\n",
      "Epoch 00522: val_loss improved from 0.13757 to 0.13685, saving model to ./model/final522-0.1369.hdf5\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.13685\n",
      "\n",
      "Epoch 00547: val_loss improved from 0.13685 to 0.13645, saving model to ./model/final547-0.1365.hdf5\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.13645\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.13645\n",
      "\n",
      "Epoch 00550: val_loss improved from 0.13645 to 0.13331, saving model to ./model/final550-0.1333.hdf5\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.13331\n",
      "\n",
      "Epoch 00584: val_loss improved from 0.13331 to 0.13078, saving model to ./model/final584-0.1308.hdf5\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.13078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00589: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.13078\n",
      "\n",
      "Epoch 00620: val_loss improved from 0.13078 to 0.12944, saving model to ./model/final620-0.1294.hdf5\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.12944\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.12944\n",
      "\n",
      "Epoch 00623: val_loss improved from 0.12944 to 0.12874, saving model to ./model/final623-0.1287.hdf5\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.12874\n",
      "\n",
      "Epoch 00682: val_loss improved from 0.12874 to 0.12699, saving model to ./model/final682-0.1270.hdf5\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.12699\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.12699\n",
      "\n",
      "Epoch 00685: val_loss improved from 0.12699 to 0.12692, saving model to ./model/final685-0.1269.hdf5\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.12692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00743: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.12692\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.12692\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, validation_split=0.33, epochs=1000, batch_size=500,\n",
    "                    verbose=0, callbacks=[early_stopping_callback, checkpointer_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 381 samples, validate on 188 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21795325308>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split=0.33, epochs=0, batch_size=600, \n",
    "          verbose=1, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 - 0s - loss: 0.1148 - accuracy: 0.9525\n",
      "\n",
      " Accuracy: 0.9525\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = load_model('model/final1000-0.1467.hdf5')\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vloss=history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_acc=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_len = np.arange(len(y_acc))\n",
    "plt.figure(figsize=(13,6))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=2)\n",
    "plt.ylim(0.0, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제 2번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X= digits.data\n",
    "Y= digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#random seed = 2020\n",
    "#model 구현할때 softmax\n",
    "#train_test_split - test_size= 0.2\n",
    "#model.fit 할때 validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 1,210\n",
      "Trainable params: 1,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(64,), activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1437 samples, validate on 360 samples\n",
      "Epoch 1/5000\n",
      "1437/1437 [==============================] - 0s 222us/sample - loss: 5.4885 - accuracy: 0.2109 - val_loss: 3.1083 - val_accuracy: 0.2806\n",
      "Epoch 2/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 2.2854 - accuracy: 0.2756 - val_loss: 2.1621 - val_accuracy: 0.2639\n",
      "Epoch 3/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 1.7680 - accuracy: 0.3660 - val_loss: 1.7946 - val_accuracy: 0.3639\n",
      "Epoch 4/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 1.4867 - accuracy: 0.4760 - val_loss: 1.5090 - val_accuracy: 0.4528\n",
      "Epoch 5/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 1.2382 - accuracy: 0.5908 - val_loss: 1.3314 - val_accuracy: 0.5556\n",
      "Epoch 6/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 1.0129 - accuracy: 0.6903 - val_loss: 1.1331 - val_accuracy: 0.6250\n",
      "Epoch 7/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.7885 - accuracy: 0.7474 - val_loss: 0.9412 - val_accuracy: 0.7000\n",
      "Epoch 8/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.5770 - accuracy: 0.8225 - val_loss: 0.7946 - val_accuracy: 0.7722\n",
      "Epoch 9/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.4514 - accuracy: 0.8650 - val_loss: 0.6704 - val_accuracy: 0.8056\n",
      "Epoch 10/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.3778 - accuracy: 0.8824 - val_loss: 0.6218 - val_accuracy: 0.8250\n",
      "Epoch 11/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.3330 - accuracy: 0.8970 - val_loss: 0.5681 - val_accuracy: 0.8361\n",
      "Epoch 12/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.2937 - accuracy: 0.9123 - val_loss: 0.5437 - val_accuracy: 0.8361\n",
      "Epoch 13/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.2626 - accuracy: 0.9186 - val_loss: 0.5062 - val_accuracy: 0.8583\n",
      "Epoch 14/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.2394 - accuracy: 0.9283 - val_loss: 0.4921 - val_accuracy: 0.8750\n",
      "Epoch 15/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.2202 - accuracy: 0.9311 - val_loss: 0.4600 - val_accuracy: 0.8639\n",
      "Epoch 16/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.1981 - accuracy: 0.9422 - val_loss: 0.4550 - val_accuracy: 0.8667\n",
      "Epoch 17/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.1859 - accuracy: 0.9422 - val_loss: 0.4509 - val_accuracy: 0.8722\n",
      "Epoch 18/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.1713 - accuracy: 0.9499 - val_loss: 0.4257 - val_accuracy: 0.8806\n",
      "Epoch 19/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.1592 - accuracy: 0.9527 - val_loss: 0.4272 - val_accuracy: 0.8778\n",
      "Epoch 20/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.1469 - accuracy: 0.9548 - val_loss: 0.4202 - val_accuracy: 0.8861\n",
      "Epoch 21/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.1365 - accuracy: 0.9617 - val_loss: 0.4118 - val_accuracy: 0.8861\n",
      "Epoch 22/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.1295 - accuracy: 0.9645 - val_loss: 0.4015 - val_accuracy: 0.8944\n",
      "Epoch 23/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.1222 - accuracy: 0.9687 - val_loss: 0.3956 - val_accuracy: 0.8917\n",
      "Epoch 24/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.1137 - accuracy: 0.9687 - val_loss: 0.3981 - val_accuracy: 0.9000\n",
      "Epoch 25/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.1062 - accuracy: 0.9701 - val_loss: 0.3857 - val_accuracy: 0.8889\n",
      "Epoch 26/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.1023 - accuracy: 0.9729 - val_loss: 0.3859 - val_accuracy: 0.8944\n",
      "Epoch 27/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0968 - accuracy: 0.9722 - val_loss: 0.3962 - val_accuracy: 0.8944\n",
      "Epoch 28/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0904 - accuracy: 0.9743 - val_loss: 0.3872 - val_accuracy: 0.8917\n",
      "Epoch 29/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0868 - accuracy: 0.9749 - val_loss: 0.3813 - val_accuracy: 0.8944\n",
      "Epoch 30/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0818 - accuracy: 0.9777 - val_loss: 0.3759 - val_accuracy: 0.8944\n",
      "Epoch 31/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0781 - accuracy: 0.9791 - val_loss: 0.3667 - val_accuracy: 0.8972\n",
      "Epoch 32/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0729 - accuracy: 0.9812 - val_loss: 0.3791 - val_accuracy: 0.8944\n",
      "Epoch 33/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0704 - accuracy: 0.9819 - val_loss: 0.3664 - val_accuracy: 0.9056\n",
      "Epoch 34/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0668 - accuracy: 0.9826 - val_loss: 0.3758 - val_accuracy: 0.8972\n",
      "Epoch 35/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0643 - accuracy: 0.9833 - val_loss: 0.3758 - val_accuracy: 0.9028\n",
      "Epoch 36/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0615 - accuracy: 0.9847 - val_loss: 0.3746 - val_accuracy: 0.9056\n",
      "Epoch 37/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0590 - accuracy: 0.9861 - val_loss: 0.3806 - val_accuracy: 0.8944\n",
      "Epoch 38/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0558 - accuracy: 0.9875 - val_loss: 0.3814 - val_accuracy: 0.8972\n",
      "Epoch 39/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0525 - accuracy: 0.9868 - val_loss: 0.3721 - val_accuracy: 0.8889\n",
      "Epoch 40/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0514 - accuracy: 0.9875 - val_loss: 0.3802 - val_accuracy: 0.8972\n",
      "Epoch 41/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0483 - accuracy: 0.9889 - val_loss: 0.3795 - val_accuracy: 0.8972\n",
      "Epoch 42/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0465 - accuracy: 0.9896 - val_loss: 0.3687 - val_accuracy: 0.9056\n",
      "Epoch 43/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0455 - accuracy: 0.9882 - val_loss: 0.3737 - val_accuracy: 0.9000\n",
      "Epoch 44/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0411 - accuracy: 0.9903 - val_loss: 0.3831 - val_accuracy: 0.8972\n",
      "Epoch 45/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0428 - accuracy: 0.9923 - val_loss: 0.3667 - val_accuracy: 0.9000\n",
      "Epoch 46/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0385 - accuracy: 0.9910 - val_loss: 0.3872 - val_accuracy: 0.9083\n",
      "Epoch 47/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0367 - accuracy: 0.9910 - val_loss: 0.3886 - val_accuracy: 0.9056\n",
      "Epoch 48/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0340 - accuracy: 0.9937 - val_loss: 0.3744 - val_accuracy: 0.9056\n",
      "Epoch 49/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0330 - accuracy: 0.9937 - val_loss: 0.3691 - val_accuracy: 0.9111\n",
      "Epoch 50/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0305 - accuracy: 0.9937 - val_loss: 0.3810 - val_accuracy: 0.9111\n",
      "Epoch 51/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0298 - accuracy: 0.9944 - val_loss: 0.3804 - val_accuracy: 0.9139\n",
      "Epoch 52/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0281 - accuracy: 0.9958 - val_loss: 0.3735 - val_accuracy: 0.9028\n",
      "Epoch 53/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0279 - accuracy: 0.9958 - val_loss: 0.3882 - val_accuracy: 0.9028\n",
      "Epoch 54/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0255 - accuracy: 0.9972 - val_loss: 0.3752 - val_accuracy: 0.9139\n",
      "Epoch 55/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0241 - accuracy: 0.9965 - val_loss: 0.3955 - val_accuracy: 0.9083\n",
      "Epoch 56/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0240 - accuracy: 0.9965 - val_loss: 0.3867 - val_accuracy: 0.9056\n",
      "Epoch 57/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0227 - accuracy: 0.9972 - val_loss: 0.3830 - val_accuracy: 0.9111\n",
      "Epoch 58/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0212 - accuracy: 0.9979 - val_loss: 0.3806 - val_accuracy: 0.9111\n",
      "Epoch 59/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0210 - accuracy: 0.9979 - val_loss: 0.4036 - val_accuracy: 0.8972\n",
      "Epoch 60/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0198 - accuracy: 0.9972 - val_loss: 0.3921 - val_accuracy: 0.9028\n",
      "Epoch 61/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0202 - accuracy: 0.9972 - val_loss: 0.3913 - val_accuracy: 0.9056\n",
      "Epoch 62/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0184 - accuracy: 0.9986 - val_loss: 0.3785 - val_accuracy: 0.9111\n",
      "Epoch 63/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0184 - accuracy: 0.9986 - val_loss: 0.3988 - val_accuracy: 0.9056\n",
      "Epoch 64/5000\n",
      "1437/1437 [==============================] - 0s 36us/sample - loss: 0.0180 - accuracy: 0.9979 - val_loss: 0.3973 - val_accuracy: 0.9028\n",
      "Epoch 65/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0168 - accuracy: 0.9993 - val_loss: 0.3961 - val_accuracy: 0.9083\n",
      "Epoch 66/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0157 - accuracy: 0.9979 - val_loss: 0.3867 - val_accuracy: 0.9056\n",
      "Epoch 67/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0151 - accuracy: 0.9986 - val_loss: 0.3931 - val_accuracy: 0.9056\n",
      "Epoch 68/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0145 - accuracy: 0.9993 - val_loss: 0.3918 - val_accuracy: 0.9111\n",
      "Epoch 69/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0141 - accuracy: 0.9993 - val_loss: 0.3962 - val_accuracy: 0.9056\n",
      "Epoch 70/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0134 - accuracy: 0.9986 - val_loss: 0.4071 - val_accuracy: 0.9083\n",
      "Epoch 71/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0130 - accuracy: 0.9986 - val_loss: 0.3975 - val_accuracy: 0.9139\n",
      "Epoch 72/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0124 - accuracy: 0.9993 - val_loss: 0.4072 - val_accuracy: 0.9111\n",
      "Epoch 73/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0122 - accuracy: 0.9993 - val_loss: 0.4086 - val_accuracy: 0.9056\n",
      "Epoch 74/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0119 - accuracy: 0.9993 - val_loss: 0.3990 - val_accuracy: 0.9028\n",
      "Epoch 75/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0119 - accuracy: 0.9986 - val_loss: 0.4110 - val_accuracy: 0.9111\n",
      "Epoch 76/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0113 - accuracy: 0.9993 - val_loss: 0.3963 - val_accuracy: 0.9083\n",
      "Epoch 77/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0106 - accuracy: 0.9993 - val_loss: 0.4087 - val_accuracy: 0.9111\n",
      "Epoch 78/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9083\n",
      "Epoch 79/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.9083\n",
      "Epoch 80/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9028\n",
      "Epoch 81/5000\n",
      "1437/1437 [==============================] - 0s 36us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9139\n",
      "Epoch 82/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9083\n",
      "Epoch 83/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9056\n",
      "Epoch 84/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.9139\n",
      "Epoch 85/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9111\n",
      "Epoch 86/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.9111\n",
      "Epoch 87/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9083\n",
      "Epoch 88/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9083\n",
      "Epoch 89/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9139\n",
      "Epoch 90/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9056\n",
      "Epoch 91/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9167\n",
      "Epoch 92/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9083\n",
      "Epoch 93/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9111\n",
      "Epoch 94/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9139\n",
      "Epoch 95/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9083\n",
      "Epoch 96/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9167\n",
      "Epoch 97/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9111\n",
      "Epoch 98/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9111\n",
      "Epoch 99/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.9111\n",
      "Epoch 100/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9139\n",
      "Epoch 101/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.9194\n",
      "Epoch 102/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9111\n",
      "Epoch 103/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9167\n",
      "Epoch 104/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.9139\n",
      "Epoch 105/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.9167\n",
      "Epoch 106/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.9111\n",
      "Epoch 107/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9111\n",
      "Epoch 108/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4631 - val_accuracy: 0.9167\n",
      "Epoch 109/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9167\n",
      "Epoch 110/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.9139\n",
      "Epoch 111/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9139\n",
      "Epoch 112/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.9139\n",
      "Epoch 113/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.9111\n",
      "Epoch 114/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.9167\n",
      "Epoch 115/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.9139\n",
      "Epoch 116/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.9167\n",
      "Epoch 117/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9139\n",
      "Epoch 118/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.9167\n",
      "Epoch 119/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.9111\n",
      "Epoch 120/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.9194\n",
      "Epoch 121/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9139\n",
      "Epoch 122/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.9139\n",
      "Epoch 123/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9222\n",
      "Epoch 124/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9194\n",
      "Epoch 125/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9139\n",
      "Epoch 126/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.9139\n",
      "Epoch 127/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.9167\n",
      "Epoch 128/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.9194\n",
      "Epoch 129/5000\n",
      "1437/1437 [==============================] - 0s 38us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.9139\n",
      "Epoch 130/5000\n",
      "1437/1437 [==============================] - 0s 37us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9139\n",
      "Epoch 131/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.9167\n",
      "Epoch 132/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.9111\n",
      "Epoch 133/5000\n",
      "1437/1437 [==============================] - 0s 39us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17759629608>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y,validation_split=0.2,epochs=5000, batch_size=30, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797/1797 - 0s - loss: 0.1021 - accuracy: 0.9833\n",
      "\n",
      " Accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
